{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Getting familiar with TensorFlow\n",
    "\n",
    "*TensorFlow* is one of the most popular deep learning framework developed by Google. If you are new to TensorFlow, please read and play with the sample in [Getting started with TensorFlow](https://www.tensorflow.org/get_started/get_started) to get started.\n",
    "\n",
    "* <b>Learning Objective:</b> In Problem 1, you implemented a fully connected network from scratch on your own. Very tedious to do it all by yourself, right? Well, we actually feel the same thing, that's why we are using tools instead of doing everything from scratch. For this part of the assignment, we will familiarize you with a widely-used deep learning framework developed by Google, TensorFlow and walk you through convolutional neural networks and show how to train them.\n",
    "* <b>Provided Codes:</b> We provide the Template class for a simple CNN model as BaseModel, predefined skeletons for conv2d() and max_pool(), as well as the dataset preprocessing parts.\n",
    "* <b>TODOs:</b> You are asked to implement the BaseModel following the detailed instructions and design your own model in YourModel to achieve a reasonably good performance for classification task on CIFAR-10 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/tensorflow_1.4_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/anaconda/envs/tensorflow_1.4_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/anaconda/envs/tensorflow_1.4_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/anaconda/envs/tensorflow_1.4_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/anaconda/envs/tensorflow_1.4_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/anaconda/envs/tensorflow_1.4_cpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/anaconda/envs/tensorflow_1.4_cpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/anaconda/envs/tensorflow_1.4_cpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/anaconda/envs/tensorflow_1.4_cpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/anaconda/envs/tensorflow_1.4_cpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/anaconda/envs/tensorflow_1.4_cpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/anaconda/envs/tensorflow_1.4_cpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version 1.14.0\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "# Add whatever you want\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from lib.datasets import CIFAR10_tf\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# We recommend to use tensorflow==1.14.0\n",
    "print(\"TensorFlow Version {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets\n",
    "Download [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz) and load the dataset. In this assignment, we will use the standard 50,000 images for training and 10,000 images for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "num_training = 49000\n",
    "num_validation = 50000 - num_training\n",
    "num_test = 10000\n",
    "\n",
    "data = CIFAR10_tf(num_training=num_training,\n",
    "                  num_validation=num_validation,\n",
    "                  num_test=num_test)\n",
    "\n",
    "# Load cifar-10 data\n",
    "X_train, Y_train = data['data_train'], data['labels_train']\n",
    "X_val, Y_val = data['data_val'], data['labels_val']\n",
    "X_test, Y_test = data['data_test'], data['labels_test']\n",
    "\n",
    "# Check the shape of the dataset\n",
    "assert X_train.shape == (num_training, 32, 32, 3)\n",
    "assert Y_train.shape == (num_training, )\n",
    "assert X_val.shape == (num_validation, 32, 32, 3)\n",
    "assert Y_val.shape == (num_validation, )\n",
    "assert X_test.shape == (num_test, 32, 32, 3)\n",
    "assert Y_test.shape == (10000, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2-1 [10pt]\n",
    "\n",
    "Using the code provided, implement a neural network architecture with an optimization routine according to the specification provided below.\n",
    "\n",
    "**Model:**\n",
    "- Input image with the size 32x32x3\n",
    "- 7x7 convolutional layer with 32 filters, stride of 1, and padding 'SAME'\n",
    "- ReLU activation layer\n",
    "- 3x3 max pooling layer with a stride of 2\n",
    "- 5x5 convolutional layer with 64 filters, stride of 1, and padding 'SAME'\n",
    "- ReLU activation layer\n",
    "- 3x3 max pooling layer with a stride of 2\n",
    "- Flatten layer (8x8x64 -> 4096)\n",
    "- Fully-connected layer with 384 output units (4096 -> 384)\n",
    "- ReLU activation layer\n",
    "- Fully-connected layer with 10 output units (384 -> 10)\n",
    "- Output logits (10)\n",
    "\n",
    "**Optimizer:**\n",
    "- Adam optimizer\n",
    "\n",
    "**Learning rate:**\n",
    "- Set start learning rate as 5e-4 and apply exponential decay every 500 steps with a base of 0.96\n",
    "- Use 'tf.train.exponential_decay' and 'tf.train.AdamOptimizer'\n",
    "\n",
    "**Loss:**\n",
    "- Softmax cross entropy loss\n",
    "- Use 'tf.nn.softmax_cross_entropy_with_logits_v2'\n",
    "\n",
    "\n",
    "Your model **should** achieve about 55% accuracy on test set in 5 epochs using provided evaluation code.\n",
    "\n",
    "You can modify the template code as you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define your layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define max pooling and conv layers\n",
    "\n",
    "def conv2d(input, kernel_size, stride, num_filter):\n",
    "    stride_shape = [1, stride, stride, 1]\n",
    "    filter_shape = [kernel_size, kernel_size, input.get_shape()[3], num_filter]\n",
    "\n",
    "    W = tf.get_variable('w', filter_shape, tf.float32, tf.random_normal_initializer(0.0, 0.02))\n",
    "    b = tf.get_variable('b', [1, 1, 1, num_filter], initializer=tf.constant_initializer(0.0))\n",
    "    return tf.nn.conv2d(input, W, stride_shape, padding='SAME') + b\n",
    "\n",
    "def max_pool(input, kernel_size, stride):\n",
    "    ksize = [1, kernel_size, kernel_size, 1]\n",
    "    strides = [1, stride, stride, 1]\n",
    "    return tf.nn.max_pool(input, ksize=ksize, strides=strides, padding='SAME')\n",
    "\n",
    "#############################################################################\n",
    "# TODO: Complete the following functions                                    #\n",
    "#############################################################################\n",
    "def flatten(input):\n",
    "    \"\"\"\n",
    "        - input: input tensors\n",
    "    \"\"\"\n",
    "    return tf.contrib.layers.flatten(inputs=input)\n",
    "\n",
    "def fc(input, num_output):\n",
    "    \"\"\"\n",
    "        - input: input tensors\n",
    "        - num_output: int, the output dimension\n",
    "    \"\"\"\n",
    "    return tf.contrib.layers.fully_connected(input,num_output,activation_fn=None)\n",
    "#############################################################################\n",
    "#                             END OF YOUR CODE                              #\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(object):\n",
    "    def __init__(self):\n",
    "        self.num_epoch = 5\n",
    "        self.batch_size = 64\n",
    "        self.log_step = 50\n",
    "        self._build_model()\n",
    "\n",
    "    def _model(self):\n",
    "        print('-' * 5 + '  Sample model  ' + '-' * 5)\n",
    "\n",
    "        print('intput layer: ' + str(self.X.get_shape()))\n",
    "\n",
    "        with tf.variable_scope('conv1'):\n",
    "            self.conv1 = conv2d(self.X, 7, 1, 32)\n",
    "            self.relu1 = tf.nn.relu(self.conv1)\n",
    "            self.pool1 = max_pool(self.relu1, 3, 2)            \n",
    "            print('conv1 layer: ' + str(self.pool1.get_shape()))\n",
    "\n",
    "        with tf.variable_scope('conv2'):\n",
    "            #############################################################################\n",
    "            # TODO: Complete the following functions                                    #\n",
    "            #############################################################################\n",
    "            self.conv2 = conv2d(self.pool1, 5, 1, 64)\n",
    "            self.relu2 = tf.nn.relu(self.conv2)\n",
    "            self.pool2 = max_pool(self.relu2, 3, 2)            \n",
    "            #############################################################################\n",
    "            #                             END OF YOUR CODE                              #\n",
    "            #############################################################################\n",
    "            print('conv2 layer: ' + str(self.pool2.get_shape()))\n",
    "\n",
    "        #############################################################################\n",
    "        # TODO: Flatten the output tensor from conv2 layer                          #\n",
    "        #############################################################################\n",
    "        self.flat = flatten(self.pool2)\n",
    "        #############################################################################\n",
    "        #                             END OF YOUR CODE                              #\n",
    "        #############################################################################      \n",
    "        print('flat layer: ' + str(self.flat.get_shape()))\n",
    "\n",
    "        with tf.variable_scope('fc3'):\n",
    "            #############################################################################\n",
    "            # TODO: Complete the following functions                                    #\n",
    "            #############################################################################\n",
    "            self.fc3 = fc(self.flat,384)\n",
    "            self.relu3 = tf.nn.relu(self.fc3)\n",
    "            #############################################################################\n",
    "            #                             END OF YOUR CODE                              #\n",
    "            #############################################################################\n",
    "            print('fc3 layer: ' + str(self.relu3.get_shape()))\n",
    "            \n",
    "        with tf.variable_scope('fc4'):\n",
    "            #############################################################################\n",
    "            # TODO: Complete the following functions                                    #\n",
    "            #############################################################################\n",
    "            self.fc4 = fc(self.relu3,10)\n",
    "            #############################################################################\n",
    "            #                             END OF YOUR CODE                              #\n",
    "            #############################################################################\n",
    "            print('fc4 layer: ' + str(self.fc4.get_shape()))\n",
    "            \n",
    "        # Return the last layer\n",
    "        return self.fc4\n",
    "\n",
    "    def _input_ops(self):\n",
    "        # Placeholders\n",
    "        self.X = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "        self.Y = tf.placeholder(tf.int64, [None])\n",
    "\n",
    "        #############################################################################\n",
    "        # TODO: You can add any placeholders                                        #\n",
    "        #############################################################################\n",
    "        self.step = tf.placeholder(tf.int64)\n",
    "        self.is_train = tf.placeholder(tf.bool, name=\"is_train\");\n",
    "        self.prob1 = tf.placeholder_with_default(1.0, shape=())\n",
    "        self.prob2 = tf.placeholder_with_default(1.0, shape=())\n",
    "        #############################################################################\n",
    "        #                             END OF YOUR CODE                              #\n",
    "        #############################################################################\n",
    "\n",
    "    def _build_optimizer(self):\n",
    "        #############################################################################\n",
    "        # TODO: Adam optimizer 'self.train_op' that minimizes 'self.loss_op'        #\n",
    "        #############################################################################\n",
    "        learning_rate = tf.train.exponential_decay(\n",
    "            5e-4,                # Base learning rate.\n",
    "            self.step,  # Current index into the dataset.\n",
    "            500,          # Decay step.\n",
    "            0.96,                # Decay rate.\n",
    "            staircase=True\n",
    "        )\n",
    "        self.train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss=self.loss_op)\n",
    "        #############################################################################\n",
    "        #                             END OF YOUR CODE                              #\n",
    "        #############################################################################\n",
    "        \n",
    "    def _loss(self, labels, logits):\n",
    "        #############################################################################\n",
    "        # TODO: Softmax cross entropy loss 'self.loss_op'                           #\n",
    "        #############################################################################\n",
    "        self.loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "            labels = labels,\n",
    "            logits = logits,\n",
    "        ))\n",
    "        #############################################################################\n",
    "        #                             END OF YOUR CODE                              #\n",
    "        #############################################################################\n",
    "\n",
    "    def _build_model(self):\n",
    "        # Define input variables\n",
    "        self._input_ops()\n",
    "\n",
    "        # Convert Y to one-hot vector\n",
    "        labels = tf.one_hot(self.Y, 10)\n",
    "\n",
    "        # Build a model and get logits\n",
    "        logits = self._model()\n",
    "\n",
    "        # Compute loss\n",
    "        self._loss(labels, logits)\n",
    "        \n",
    "        # Build optimizer\n",
    "        self._build_optimizer()\n",
    "\n",
    "        # Compute accuracy\n",
    "        predict = tf.argmax(logits, 1)\n",
    "        correct = tf.equal(predict, self.Y)\n",
    "        self.accuracy_op = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "        \n",
    "    def train(self, sess, X_train, Y_train, X_val, Y_val):\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        step = 0\n",
    "        losses = []\n",
    "        accuracies = []\n",
    "        print('-' * 5 + '  Start training  ' + '-' * 5)\n",
    "        for epoch in range(self.num_epoch):\n",
    "            print('train for epoch %d' % epoch)\n",
    "            for i in range(num_training // self.batch_size):\n",
    "                X_ = X_train[i * self.batch_size:(i + 1) * self.batch_size][:]\n",
    "                Y_ = Y_train[i * self.batch_size:(i + 1) * self.batch_size]\n",
    "\n",
    "                #############################################################################\n",
    "                # TODO: You can change feed data as you want                                #\n",
    "                #############################################################################\n",
    "                feed_dict = {self.X: X_, self.Y: Y_, self.step: step, self.prob1: 0.5,self.prob2: 0.8,self.is_train:True}\n",
    "                #############################################################################\n",
    "                #                             END OF YOUR CODE                              #\n",
    "                #############################################################################\n",
    "                fetches = [self.train_op, self.loss_op, self.accuracy_op]\n",
    "\n",
    "                _, loss, accuracy = sess.run(fetches, feed_dict=feed_dict)\n",
    "                losses.append(loss)\n",
    "                accuracies.append(accuracy)\n",
    "\n",
    "                if step % self.log_step == 0:\n",
    "                    print('iteration (%d): loss = %.3f, accuracy = %.3f' %\n",
    "                        (step, loss, accuracy))\n",
    "                step += 1\n",
    "\n",
    "            # Print validation results\n",
    "            print('validation for epoch %d' % epoch)\n",
    "            val_accuracy = self.evaluate(sess, X_val, Y_val)\n",
    "            print('-  epoch %d: validation accuracy = %.3f' % (epoch, val_accuracy))\n",
    "            \n",
    "        #############################################################################\n",
    "        # TODO: Plot training curve                                                 #\n",
    "        #############################################################################\n",
    "        # Graph 1. X: iteration (training step), Y: training loss\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(range(step), losses, '-o')\n",
    "        plt.xlabel('iteration')\n",
    "        plt.ylabel('training loss')\n",
    "        plt.show()\n",
    "        # Graph 2. X: iteration (training step), Y: training accuracy\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(range(step), accuracies, '-o')\n",
    "        plt.xlabel('iteration')\n",
    "        plt.ylabel('training accuracy')\n",
    "        plt.show()\n",
    "        #############################################################################\n",
    "        #                             END OF YOUR CODE                              #\n",
    "        #############################################################################\n",
    "\n",
    "    def evaluate(self, sess, X_eval, Y_eval):\n",
    "        eval_accuracy = 0.0\n",
    "        eval_iter = 0\n",
    "        for i in range(X_eval.shape[0] // self.batch_size):\n",
    "            X_ = X_eval[i * self.batch_size:(i + 1) * self.batch_size][:]\n",
    "            Y_ = Y_eval[i * self.batch_size:(i + 1) * self.batch_size]\n",
    "            \n",
    "            #############################################################################\n",
    "            # TODO: You can change feed data as you want                                #\n",
    "            #############################################################################\n",
    "            feed_dict = {self.X: X_, self.Y: Y_, self.is_train:False}\n",
    "            #############################################################################\n",
    "            #                             END OF YOUR CODE                              #\n",
    "            #############################################################################\n",
    "            accuracy = sess.run(self.accuracy_op, feed_dict=feed_dict)\n",
    "            eval_accuracy += accuracy\n",
    "            eval_iter += 1\n",
    "        return eval_accuracy / eval_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----  Sample model  -----\n",
      "intput layer: (?, 32, 32, 3)\n",
      "conv1 layer: (?, 16, 16, 32)\n",
      "conv2 layer: (?, 8, 8, 64)\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x144e71e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x144e71e50>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x144e71e50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x144e71e50>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "flat layer: (?, 4096)\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1443d9fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1443d9fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1443d9fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1443d9fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "fc3 layer: (?, 384)\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1443d9e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1443d9e90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1443d9e90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1443d9e90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "fc4 layer: (?, 10)\n",
      "-----  Start training  -----\n",
      "train for epoch 0\n",
      "iteration (0): loss = 17.672, accuracy = 0.047\n",
      "iteration (50): loss = 2.004, accuracy = 0.328\n",
      "iteration (100): loss = 2.033, accuracy = 0.250\n",
      "iteration (150): loss = 1.703, accuracy = 0.453\n",
      "iteration (200): loss = 1.663, accuracy = 0.453\n",
      "iteration (250): loss = 1.562, accuracy = 0.422\n",
      "iteration (300): loss = 1.496, accuracy = 0.359\n",
      "iteration (350): loss = 1.497, accuracy = 0.375\n",
      "iteration (400): loss = 1.487, accuracy = 0.484\n",
      "iteration (450): loss = 1.461, accuracy = 0.469\n",
      "iteration (500): loss = 1.434, accuracy = 0.516\n",
      "iteration (550): loss = 1.438, accuracy = 0.531\n",
      "iteration (600): loss = 1.707, accuracy = 0.500\n",
      "iteration (650): loss = 1.340, accuracy = 0.562\n",
      "iteration (700): loss = 1.485, accuracy = 0.438\n",
      "iteration (750): loss = 1.901, accuracy = 0.328\n",
      "validation for epoch 0\n",
      "-  epoch 0: validation accuracy = 0.536\n",
      "train for epoch 1\n",
      "iteration (800): loss = 1.373, accuracy = 0.453\n",
      "iteration (850): loss = 1.412, accuracy = 0.500\n",
      "iteration (900): loss = 1.244, accuracy = 0.531\n",
      "iteration (950): loss = 1.287, accuracy = 0.484\n",
      "iteration (1000): loss = 1.591, accuracy = 0.484\n",
      "iteration (1050): loss = 1.405, accuracy = 0.547\n",
      "iteration (1100): loss = 1.253, accuracy = 0.594\n",
      "iteration (1150): loss = 1.012, accuracy = 0.641\n",
      "iteration (1200): loss = 1.428, accuracy = 0.500\n",
      "iteration (1250): loss = 1.134, accuracy = 0.641\n",
      "iteration (1300): loss = 1.041, accuracy = 0.641\n",
      "iteration (1350): loss = 1.278, accuracy = 0.500\n",
      "iteration (1400): loss = 1.069, accuracy = 0.641\n",
      "iteration (1450): loss = 1.279, accuracy = 0.516\n",
      "iteration (1500): loss = 1.164, accuracy = 0.625\n",
      "validation for epoch 1\n",
      "-  epoch 1: validation accuracy = 0.575\n",
      "train for epoch 2\n",
      "iteration (1550): loss = 1.309, accuracy = 0.531\n",
      "iteration (1600): loss = 1.190, accuracy = 0.578\n",
      "iteration (1650): loss = 1.202, accuracy = 0.578\n",
      "iteration (1700): loss = 1.346, accuracy = 0.453\n",
      "iteration (1750): loss = 0.873, accuracy = 0.609\n",
      "iteration (1800): loss = 1.144, accuracy = 0.625\n",
      "iteration (1850): loss = 1.123, accuracy = 0.594\n",
      "iteration (1900): loss = 0.782, accuracy = 0.688\n",
      "iteration (1950): loss = 1.164, accuracy = 0.672\n",
      "iteration (2000): loss = 1.140, accuracy = 0.609\n",
      "iteration (2050): loss = 1.173, accuracy = 0.656\n",
      "iteration (2100): loss = 1.109, accuracy = 0.594\n",
      "iteration (2150): loss = 1.062, accuracy = 0.656\n",
      "iteration (2200): loss = 1.242, accuracy = 0.578\n",
      "iteration (2250): loss = 0.780, accuracy = 0.734\n",
      "validation for epoch 2\n",
      "-  epoch 2: validation accuracy = 0.610\n",
      "train for epoch 3\n",
      "iteration (2300): loss = 1.036, accuracy = 0.609\n",
      "iteration (2350): loss = 0.875, accuracy = 0.672\n",
      "iteration (2400): loss = 0.776, accuracy = 0.672\n",
      "iteration (2450): loss = 0.892, accuracy = 0.734\n",
      "iteration (2500): loss = 1.050, accuracy = 0.562\n",
      "iteration (2550): loss = 0.705, accuracy = 0.766\n",
      "iteration (2600): loss = 1.522, accuracy = 0.453\n",
      "iteration (2650): loss = 0.923, accuracy = 0.703\n",
      "iteration (2700): loss = 0.992, accuracy = 0.656\n",
      "iteration (2750): loss = 1.159, accuracy = 0.688\n",
      "iteration (2800): loss = 0.896, accuracy = 0.688\n",
      "iteration (2850): loss = 0.950, accuracy = 0.641\n",
      "iteration (2900): loss = 0.770, accuracy = 0.688\n",
      "iteration (2950): loss = 0.903, accuracy = 0.578\n",
      "iteration (3000): loss = 0.773, accuracy = 0.734\n",
      "iteration (3050): loss = 0.995, accuracy = 0.688\n",
      "validation for epoch 3\n",
      "-  epoch 3: validation accuracy = 0.627\n",
      "train for epoch 4\n",
      "iteration (3100): loss = 0.669, accuracy = 0.812\n",
      "iteration (3150): loss = 0.876, accuracy = 0.688\n",
      "iteration (3200): loss = 1.162, accuracy = 0.641\n",
      "iteration (3250): loss = 0.922, accuracy = 0.719\n",
      "iteration (3300): loss = 0.859, accuracy = 0.719\n",
      "iteration (3350): loss = 0.939, accuracy = 0.750\n",
      "iteration (3400): loss = 0.670, accuracy = 0.719\n",
      "iteration (3450): loss = 0.811, accuracy = 0.609\n",
      "iteration (3500): loss = 0.807, accuracy = 0.672\n",
      "iteration (3550): loss = 1.085, accuracy = 0.672\n",
      "iteration (3600): loss = 0.931, accuracy = 0.672\n",
      "iteration (3650): loss = 0.769, accuracy = 0.656\n",
      "iteration (3700): loss = 0.825, accuracy = 0.672\n",
      "iteration (3750): loss = 0.745, accuracy = 0.766\n",
      "iteration (3800): loss = 0.888, accuracy = 0.703\n",
      "validation for epoch 4\n",
      "-  epoch 4: validation accuracy = 0.608\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** test accuracy: 0.597\n",
      "Model saved in lib/tf_models/problem2/csci-599_sample.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Clear old computation graphs\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Train our sample model\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)) as sess:\n",
    "    with tf.device('/cpu:0'):\n",
    "        model = BaseModel()\n",
    "        model.train(sess, X_train, Y_train, X_val, Y_val)\n",
    "        accuracy = model.evaluate(sess, X_test, Y_test)\n",
    "        print('***** test accuracy: %.3f' % accuracy)\n",
    "        saver = tf.train.Saver()\n",
    "        model_path = saver.save(sess, \"lib/tf_models/problem2/csci-599_sample.ckpt\")\n",
    "        print(\"Model saved in %s\" % model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2-2 [15pt]\n",
    "\n",
    "Implement your own model. \n",
    "\n",
    "You can modify the template code as you want and you can use GPU for fast training. For GPU usage, simply change the following line of the training block:  \n",
    "from `with tf.device('/cpu:0')` to `with tf.device('/GPU:0')` and you can set your desired device number.\n",
    "\n",
    "These are the techniques that you can try:\n",
    "- Data preprocessing\n",
    "- Data augmentation\n",
    "- Batch normalization\n",
    "- Dropout\n",
    "- More convolutional layers\n",
    "- More training epochs\n",
    "- Learning rate decay\n",
    "- Any other models and techniqes\n",
    "\n",
    "The rubrics for this question is:\n",
    "* 15 points when test accuracy >= 75%\n",
    "* 10 points when test accuracy >= 70%\n",
    "* 5 points when test accuracy >= 60%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YourModel(BaseModel):\n",
    "    def __init__(self):\n",
    "        super(YourModel, self).__init__()\n",
    "        self.num_epoch = 10\n",
    "\n",
    "    def _model(self):\n",
    "        print('-' * 5 + '  Your model  ' + '-' * 5)\n",
    "\n",
    "        #############################################################################\n",
    "        # TODO: Implement you own model here                                        #\n",
    "        #############################################################################\n",
    "        print('-' * 5 + '  YourModel  ' + '-' * 5)\n",
    "        print('intput layer: ' + str(self.X.get_shape()))\n",
    "\n",
    "        with tf.variable_scope('conv1'):\n",
    "            self.conv1 = conv2d(self.X, 3, 1, 32)\n",
    "            self.relu1 = tf.nn.relu(self.conv1)\n",
    "        with tf.variable_scope('conv1_2'):\n",
    "            self.conv1_2 = conv2d(self.relu1, 3, 1, 32)\n",
    "            self.relu1_2 = tf.nn.relu(self.conv1_2)\n",
    "            self.pool1 = max_pool(self.relu1_2, 3, 2) \n",
    "            self.norm1 = tf.layers.batch_normalization(self.pool1)\n",
    "            print('conv1 layer: ' + str(self.norm1.get_shape()))\n",
    "\n",
    "        with tf.variable_scope('conv2'):\n",
    "            self.conv2 = conv2d(self.norm1, 3, 1, 64)\n",
    "            self.relu2 = tf.nn.relu(self.conv2)\n",
    "        with tf.variable_scope('conv2_2'):\n",
    "            self.conv2_2 = conv2d(self.relu2, 3, 1, 64)\n",
    "            self.relu2_2 = tf.nn.relu(self.conv2_2)\n",
    "            self.pool2 = max_pool(self.relu2_2, 3, 2) \n",
    "            self.norm2 = tf.layers.batch_normalization(self.pool2)\n",
    "            print('conv2 layer: ' + str(self.norm2.get_shape()))\n",
    "            \n",
    "        with tf.variable_scope('conv3'):\n",
    "            self.conv3 = conv2d(self.norm2, 3, 1, 128)\n",
    "            self.relu3 = tf.nn.relu(self.conv3)\n",
    "        with tf.variable_scope('conv3_2'):\n",
    "            self.conv3_2 = conv2d(self.relu3, 3, 1, 128)\n",
    "            self.relu3_2 = tf.nn.relu(self.conv3_2)\n",
    "            self.pool3 = max_pool(self.relu3_2, 3, 2) \n",
    "            self.norm3 = tf.layers.batch_normalization(self.pool3)\n",
    "            print('conv3 layer: ' + str(self.norm3.get_shape()))\n",
    "        \n",
    "        self.flat = flatten(self.norm3)    \n",
    "        print('flat layer: ' + str(self.flat.get_shape()))\n",
    "        '''\n",
    "        with tf.variable_scope('fc3'):\n",
    "            self.fc3 = fc(self.flat,1024)\n",
    "            self.relu3 = tf.nn.relu(self.fc3)\n",
    "            self.norm3 = tf.layers.batch_normalization(self.relu3)\n",
    "            self.dropout3 = tf.nn.dropout(self.norm3, self.prob1)\n",
    "            print('fc3 layer: ' + str(self.dropout3.get_shape()))\n",
    "        '''\n",
    "        with tf.variable_scope('fc4'):\n",
    "            self.fc4 = fc(self.flat,512)\n",
    "            self.relu4 = tf.nn.relu(self.fc4)\n",
    "            self.norm4 = tf.layers.batch_normalization(self.relu4)\n",
    "            self.dropout4 = tf.nn.dropout(self.norm4, self.prob1)\n",
    "            print('fc4 layer: ' + str(self.dropout4.get_shape()))\n",
    "            \n",
    "        \n",
    "        with tf.variable_scope('fc5'):\n",
    "            self.fc5 = fc(self.dropout4,256)\n",
    "            self.relu5 = tf.nn.relu(self.fc5)\n",
    "            self.norm5 = tf.layers.batch_normalization(self.relu5)\n",
    "            self.dropout5 = tf.nn.dropout(self.norm5, self.prob2)\n",
    "            print('fc5 layer: ' + str(self.dropout5.get_shape()))\n",
    "        \n",
    "        with tf.variable_scope('fc6'):\n",
    "            self.fc6 = fc(self.dropout5,10)\n",
    "\n",
    "            print('fc6 layer: ' + str(self.fc6.get_shape()))\n",
    "            \n",
    "        # Return the last layer\n",
    "        return self.fc6\n",
    "        #############################################################################\n",
    "        #                             END OF YOUR CODE                              #\n",
    "        #############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----  Your model  -----\n",
      "-----  YourModel  -----\n",
      "intput layer: (?, 32, 32, 3)\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x142f4be50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x142f4be50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x142f4be50>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x142f4be50>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "conv1 layer: (?, 16, 16, 32)\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x143a74a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x143a74a10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x143a74a10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x143a74a10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "conv2 layer: (?, 8, 8, 64)\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x145c0aa90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x145c0aa90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x145c0aa90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x145c0aa90>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "conv3 layer: (?, 4, 4, 128)\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x14429e0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x14429e0d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x14429e0d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x14429e0d0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "flat layer: (?, 2048)\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x144e62210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x144e62210>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x144e62210>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x144e62210>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x142879fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x142879fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x142879fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x142879fd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "fc4 layer: (?, 512)\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1455f7410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1455f7410>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1455f7410>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x1455f7410>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x144e626d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x144e626d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x144e626d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BatchNormalization.call of <tensorflow.python.layers.normalization.BatchNormalization object at 0x144e626d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "fc5 layer: (?, 256)\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x14561fa10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x14561fa10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x14561fa10>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x14561fa10>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "fc5 layer: (?, 10)\n",
      "-----  Start training  -----\n",
      "train for epoch 0\n",
      "iteration (0): loss = 2.303, accuracy = 0.062\n",
      "iteration (50): loss = 2.073, accuracy = 0.234\n",
      "iteration (100): loss = 2.015, accuracy = 0.172\n",
      "iteration (150): loss = 1.984, accuracy = 0.312\n",
      "iteration (200): loss = 1.584, accuracy = 0.422\n",
      "iteration (250): loss = 1.586, accuracy = 0.344\n",
      "iteration (300): loss = 1.647, accuracy = 0.422\n",
      "iteration (350): loss = 1.445, accuracy = 0.438\n",
      "iteration (400): loss = 1.461, accuracy = 0.516\n",
      "iteration (450): loss = 1.226, accuracy = 0.516\n",
      "iteration (500): loss = 1.428, accuracy = 0.438\n",
      "iteration (550): loss = 1.168, accuracy = 0.547\n",
      "iteration (600): loss = 1.172, accuracy = 0.641\n",
      "iteration (650): loss = 1.033, accuracy = 0.594\n",
      "iteration (700): loss = 1.312, accuracy = 0.562\n",
      "iteration (750): loss = 1.268, accuracy = 0.594\n",
      "validation for epoch 0\n",
      "-  epoch 0: validation accuracy = 0.674\n",
      "train for epoch 1\n",
      "iteration (800): loss = 0.977, accuracy = 0.656\n",
      "iteration (850): loss = 0.948, accuracy = 0.719\n",
      "iteration (900): loss = 0.966, accuracy = 0.656\n",
      "iteration (950): loss = 1.185, accuracy = 0.641\n",
      "iteration (1000): loss = 1.260, accuracy = 0.578\n",
      "iteration (1050): loss = 1.062, accuracy = 0.578\n",
      "iteration (1100): loss = 0.927, accuracy = 0.703\n",
      "iteration (1150): loss = 0.771, accuracy = 0.734\n",
      "iteration (1200): loss = 0.919, accuracy = 0.688\n",
      "iteration (1250): loss = 0.827, accuracy = 0.672\n",
      "iteration (1300): loss = 0.801, accuracy = 0.766\n",
      "iteration (1350): loss = 0.757, accuracy = 0.734\n",
      "iteration (1400): loss = 0.730, accuracy = 0.797\n",
      "iteration (1450): loss = 0.917, accuracy = 0.688\n",
      "iteration (1500): loss = 1.018, accuracy = 0.672\n",
      "validation for epoch 1\n",
      "-  epoch 1: validation accuracy = 0.739\n",
      "train for epoch 2\n",
      "iteration (1550): loss = 1.104, accuracy = 0.641\n",
      "iteration (1600): loss = 1.007, accuracy = 0.641\n",
      "iteration (1650): loss = 0.642, accuracy = 0.828\n",
      "iteration (1700): loss = 0.918, accuracy = 0.641\n",
      "iteration (1750): loss = 0.783, accuracy = 0.703\n",
      "iteration (1800): loss = 0.768, accuracy = 0.703\n",
      "iteration (1850): loss = 0.827, accuracy = 0.797\n",
      "iteration (1900): loss = 0.587, accuracy = 0.812\n",
      "iteration (1950): loss = 0.858, accuracy = 0.672\n",
      "iteration (2000): loss = 0.749, accuracy = 0.781\n",
      "iteration (2050): loss = 0.983, accuracy = 0.641\n",
      "iteration (2100): loss = 0.555, accuracy = 0.812\n",
      "iteration (2150): loss = 0.773, accuracy = 0.734\n",
      "iteration (2200): loss = 0.958, accuracy = 0.609\n",
      "iteration (2250): loss = 0.640, accuracy = 0.797\n",
      "validation for epoch 2\n",
      "-  epoch 2: validation accuracy = 0.751\n",
      "train for epoch 3\n",
      "iteration (2300): loss = 0.618, accuracy = 0.750\n",
      "iteration (2350): loss = 0.561, accuracy = 0.781\n",
      "iteration (2400): loss = 0.539, accuracy = 0.828\n",
      "iteration (2450): loss = 0.757, accuracy = 0.766\n",
      "iteration (2500): loss = 0.754, accuracy = 0.812\n",
      "iteration (2550): loss = 0.822, accuracy = 0.719\n",
      "iteration (2600): loss = 0.727, accuracy = 0.734\n",
      "iteration (2650): loss = 0.624, accuracy = 0.781\n",
      "iteration (2700): loss = 0.715, accuracy = 0.766\n",
      "iteration (2750): loss = 0.780, accuracy = 0.797\n",
      "iteration (2800): loss = 0.581, accuracy = 0.812\n",
      "iteration (2850): loss = 0.690, accuracy = 0.719\n",
      "iteration (2900): loss = 0.539, accuracy = 0.797\n",
      "iteration (2950): loss = 0.700, accuracy = 0.750\n",
      "iteration (3000): loss = 0.416, accuracy = 0.844\n",
      "iteration (3050): loss = 0.470, accuracy = 0.844\n",
      "validation for epoch 3\n",
      "-  epoch 3: validation accuracy = 0.786\n",
      "train for epoch 4\n",
      "iteration (3100): loss = 0.508, accuracy = 0.812\n",
      "iteration (3150): loss = 0.432, accuracy = 0.781\n",
      "iteration (3200): loss = 0.590, accuracy = 0.812\n",
      "iteration (3250): loss = 0.551, accuracy = 0.844\n",
      "iteration (3300): loss = 0.417, accuracy = 0.844\n",
      "iteration (3350): loss = 0.630, accuracy = 0.859\n",
      "iteration (3400): loss = 0.725, accuracy = 0.750\n",
      "iteration (3450): loss = 0.493, accuracy = 0.844\n",
      "iteration (3500): loss = 0.400, accuracy = 0.891\n",
      "iteration (3550): loss = 0.561, accuracy = 0.812\n",
      "iteration (3600): loss = 0.527, accuracy = 0.797\n",
      "iteration (3650): loss = 0.571, accuracy = 0.859\n",
      "iteration (3700): loss = 0.379, accuracy = 0.844\n",
      "iteration (3750): loss = 0.412, accuracy = 0.844\n",
      "iteration (3800): loss = 0.348, accuracy = 0.875\n",
      "validation for epoch 4\n",
      "-  epoch 4: validation accuracy = 0.781\n",
      "train for epoch 5\n",
      "iteration (3850): loss = 0.506, accuracy = 0.859\n",
      "iteration (3900): loss = 0.722, accuracy = 0.734\n",
      "iteration (3950): loss = 0.524, accuracy = 0.812\n",
      "iteration (4000): loss = 0.641, accuracy = 0.750\n",
      "iteration (4050): loss = 0.461, accuracy = 0.844\n",
      "iteration (4100): loss = 0.391, accuracy = 0.859\n",
      "iteration (4150): loss = 0.371, accuracy = 0.844\n",
      "iteration (4200): loss = 0.297, accuracy = 0.906\n",
      "iteration (4250): loss = 0.384, accuracy = 0.891\n",
      "iteration (4300): loss = 0.415, accuracy = 0.844\n",
      "iteration (4350): loss = 0.563, accuracy = 0.797\n",
      "iteration (4400): loss = 0.361, accuracy = 0.891\n",
      "iteration (4450): loss = 0.330, accuracy = 0.875\n",
      "iteration (4500): loss = 0.546, accuracy = 0.828\n",
      "iteration (4550): loss = 0.371, accuracy = 0.875\n",
      "validation for epoch 5\n",
      "-  epoch 5: validation accuracy = 0.800\n",
      "train for epoch 6\n",
      "iteration (4600): loss = 0.474, accuracy = 0.875\n",
      "iteration (4650): loss = 0.367, accuracy = 0.859\n",
      "iteration (4700): loss = 0.773, accuracy = 0.781\n",
      "iteration (4750): loss = 0.429, accuracy = 0.859\n",
      "iteration (4800): loss = 0.345, accuracy = 0.891\n",
      "iteration (4850): loss = 0.429, accuracy = 0.859\n",
      "iteration (4900): loss = 0.436, accuracy = 0.859\n",
      "iteration (4950): loss = 0.377, accuracy = 0.859\n",
      "iteration (5000): loss = 0.290, accuracy = 0.906\n",
      "iteration (5050): loss = 0.305, accuracy = 0.906\n",
      "iteration (5100): loss = 0.421, accuracy = 0.906\n",
      "iteration (5150): loss = 0.372, accuracy = 0.875\n",
      "iteration (5200): loss = 0.437, accuracy = 0.844\n",
      "iteration (5250): loss = 0.136, accuracy = 0.984\n",
      "iteration (5300): loss = 0.380, accuracy = 0.812\n",
      "iteration (5350): loss = 0.310, accuracy = 0.875\n",
      "validation for epoch 6\n",
      "-  epoch 6: validation accuracy = 0.801\n",
      "train for epoch 7\n",
      "iteration (5400): loss = 0.314, accuracy = 0.875\n",
      "iteration (5450): loss = 0.323, accuracy = 0.844\n",
      "iteration (5500): loss = 0.362, accuracy = 0.875\n",
      "iteration (5550): loss = 0.438, accuracy = 0.844\n",
      "iteration (5600): loss = 0.383, accuracy = 0.875\n",
      "iteration (5650): loss = 0.213, accuracy = 0.906\n",
      "iteration (5700): loss = 0.347, accuracy = 0.875\n",
      "iteration (5750): loss = 0.272, accuracy = 0.875\n",
      "iteration (5800): loss = 0.485, accuracy = 0.844\n",
      "iteration (5850): loss = 0.301, accuracy = 0.906\n",
      "iteration (5900): loss = 0.169, accuracy = 0.938\n",
      "iteration (5950): loss = 0.181, accuracy = 0.953\n",
      "iteration (6000): loss = 0.246, accuracy = 0.953\n",
      "iteration (6050): loss = 0.284, accuracy = 0.875\n",
      "iteration (6100): loss = 0.418, accuracy = 0.859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation for epoch 7\n",
      "-  epoch 7: validation accuracy = 0.801\n",
      "train for epoch 8\n",
      "iteration (6150): loss = 0.356, accuracy = 0.891\n",
      "iteration (6200): loss = 0.240, accuracy = 0.938\n",
      "iteration (6250): loss = 0.140, accuracy = 0.953\n",
      "iteration (6300): loss = 0.279, accuracy = 0.891\n",
      "iteration (6350): loss = 0.322, accuracy = 0.891\n",
      "iteration (6400): loss = 0.103, accuracy = 0.984\n",
      "iteration (6450): loss = 0.250, accuracy = 0.891\n",
      "iteration (6500): loss = 0.323, accuracy = 0.906\n",
      "iteration (6550): loss = 0.149, accuracy = 0.953\n",
      "iteration (6600): loss = 0.207, accuracy = 0.938\n",
      "iteration (6650): loss = 0.296, accuracy = 0.891\n",
      "iteration (6700): loss = 0.178, accuracy = 0.938\n",
      "iteration (6750): loss = 0.262, accuracy = 0.906\n",
      "iteration (6800): loss = 0.288, accuracy = 0.922\n",
      "iteration (6850): loss = 0.240, accuracy = 0.906\n",
      "validation for epoch 8\n",
      "-  epoch 8: validation accuracy = 0.790\n",
      "train for epoch 9\n",
      "iteration (6900): loss = 0.210, accuracy = 0.938\n",
      "iteration (6950): loss = 0.412, accuracy = 0.875\n",
      "iteration (7000): loss = 0.337, accuracy = 0.891\n",
      "iteration (7050): loss = 0.221, accuracy = 0.922\n",
      "iteration (7100): loss = 0.353, accuracy = 0.875\n",
      "iteration (7150): loss = 0.159, accuracy = 0.938\n",
      "iteration (7200): loss = 0.156, accuracy = 0.938\n",
      "iteration (7250): loss = 0.223, accuracy = 0.953\n",
      "iteration (7300): loss = 0.191, accuracy = 0.938\n",
      "iteration (7350): loss = 0.157, accuracy = 0.953\n",
      "iteration (7400): loss = 0.301, accuracy = 0.875\n",
      "iteration (7450): loss = 0.156, accuracy = 0.953\n",
      "iteration (7500): loss = 0.273, accuracy = 0.875\n",
      "iteration (7550): loss = 0.113, accuracy = 0.984\n",
      "iteration (7600): loss = 0.229, accuracy = 0.938\n",
      "validation for epoch 9\n",
      "-  epoch 9: validation accuracy = 0.805\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** test accuracy: 0.792\n",
      "Model saved in lib/tf_models/problem2/csci-599_mine.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Clear old computation graphs\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)) as sess:\n",
    "    with tf.device('/cpu:0'):\n",
    "        model = YourModel()\n",
    "        model.train(sess, X_train, Y_train, X_val, Y_val)\n",
    "        accuracy = model.evaluate(sess, X_test, Y_test)\n",
    "        print('***** test accuracy: %.3f' % accuracy)\n",
    "        # Save your model\n",
    "        saver = tf.train.Saver()\n",
    "        model_path = saver.save(sess, \"lib/tf_models/problem2/csci-599_mine.ckpt\")\n",
    "        print(\"Model saved in %s\" % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Load your model\n",
    "model = YourModel()\n",
    "sess = tf.Session()\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, \"lib/tf_models/problem2/csci-599_mine.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
